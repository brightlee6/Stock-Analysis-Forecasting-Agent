{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Stock Analysis and Forecast AI Agent System","metadata":{}},{"cell_type":"markdown","source":"# ⚠️ IMPORTANT DISCLAIMER ⚠️\n\nThis project is a DEMONSTRATION of how to apply AI and traditional machine learning techniques to stock analysis. It is NOT intended for actual investment decisions. Please note:\n\n- This is an educational project demonstrating AI/ML applications\n- It does NOT provide investment advice or recommendations\n- The forecasts and analyses are for demonstration purposes only\n- Do NOT use this for actual investment decisions\n- The developers take NO responsibility for any investment decisions made using this tool\n- This project is designed to help beginners understand how AI can be applied to traditional ML problems","metadata":{}},{"cell_type":"markdown","source":"# Introduction\n\nThis notebook implements a comprehensive stock analysis system with the following components:\n\n1. [Stock Data Management](#stock-data)\n2. [Holdout Validation Model](#holdout)\n3. [Hyperparameter Optimization](#hyperopt)\n4. [AI-Powered Analysis Agent](#agent)\n\nEach component is designed to work together to provide a complete stock analysis solution.\n\n## Reference\nhttps://github.com/brightlee6/Stock-Analysis-Forecasting-Agent\n","metadata":{}},{"cell_type":"markdown","source":"# Setup\n\n## Uninstall and install packages","metadata":{}},{"cell_type":"code","source":"# Remove conflicting packages from the Kaggle base environment.\n!pip uninstall -qqy kfp jupyterlab libpysal thinc spacy fastai ydata-profiling google-cloud-bigquery google-generativeai yfinance\n# Install langgraph and the packages used in this lab.\n!pip install -qU 'langgraph==0.3.21' 'langchain-google-genai==2.1.2' 'langgraph-prebuilt==0.1.7' 'yfinance==0.2.55'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T22:38:09.896674Z","iopub.execute_input":"2025-04-19T22:38:09.896966Z","iopub.status.idle":"2025-04-19T22:38:38.010496Z","shell.execute_reply.started":"2025-04-19T22:38:09.896943Z","shell.execute_reply":"2025-04-19T22:38:38.009517Z"}},"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Skipping kfp as it is not installed.\u001b[0m\u001b[33m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.8/109.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m433.9/433.9 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# check yfinance installed with right version\n# !pip list | grep yfinance","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T22:38:38.011973Z","iopub.execute_input":"2025-04-19T22:38:38.012260Z","iopub.status.idle":"2025-04-19T22:38:38.016190Z","shell.execute_reply.started":"2025-04-19T22:38:38.012237Z","shell.execute_reply":"2025-04-19T22:38:38.015183Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## Set up your API key\n\nThe `GOOGLE_API_KEY` environment variable can be set to automatically configure the underlying API. This works for both the official Gemini Python SDK and for LangChain/LangGraph. \n\nTo run the following cell, your API key must be stored it in a [Kaggle secret](https://www.kaggle.com/discussions/product-feedback/114053) named `GOOGLE_API_KEY`.\n\nIf you don't already have an API key, you can grab one from [AI Studio](https://aistudio.google.com/app/apikey). You can find [detailed instructions in the docs](https://ai.google.dev/gemini-api/docs/api-key).\n\nTo make the key available through Kaggle secrets, choose `Secrets` from the `Add-ons` menu and follow the instructions to add your key or enable it for this notebook.","metadata":{}},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\n\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\nos.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T22:38:38.017349Z","iopub.execute_input":"2025-04-19T22:38:38.017552Z","iopub.status.idle":"2025-04-19T22:38:38.230902Z","shell.execute_reply.started":"2025-04-19T22:38:38.017536Z","shell.execute_reply":"2025-04-19T22:38:38.230285Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## 1. Stock Data Management <a name=\"stock-data\"></a>\n\nThe `StockData` class handles the fetching and management of stock price data using the yfinance library.\n\n### Features:\n- Fetch historical stock closing prices\n- Save data to CSV files\n- Visualize price trends and daily returns\n- Handle data validation and error cases\n\n### Dependencies:\n- yfinance: For fetching stock data\n- pandas: For data manipulation\n- matplotlib & seaborn: For visualization","metadata":{}},{"cell_type":"code","source":"import yfinance as yf\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime\n\nclass StockData:\n    def __init__(self, ticker, start_date, end_date):\n        \"\"\"\n        Initialize a StockData object with ticker and date range.\n        \n        Args:\n            ticker (str): Stock ticker symbol (e.g., 'AAPL' for Apple)\n            start_date (str): Start date in 'YYYY-MM-DD' format\n            end_date (str): End date in 'YYYY-MM-DD' format\n        \"\"\"\n        self.ticker = ticker\n        self.start_date = start_date\n        self.end_date = end_date\n        self.dataframe = None\n        \n    def fetch_closing_prices(self):\n        \"\"\"\n        Fetch closing prices for the stock and store in dataframe.\n        \"\"\"\n        try:\n            # Convert string dates to datetime objects\n            start = datetime.strptime(self.start_date, '%Y-%m-%d')\n            end = datetime.strptime(self.end_date, '%Y-%m-%d')\n            \n            # Fetch stock data using yf.download\n            data = yf.download(self.ticker, start=start, end=end)\n            \n            # Extract closing prices and reset index to make Date a column\n            self.dataframe = data[['Close']].reset_index()\n            \n            # Rename columns for clarity\n            self.dataframe.columns = ['Date', 'Close']\n            \n            print(f\"Successfully fetched closing prices for {self.ticker}\")\n            \n        except Exception as e:\n            print(f\"Error occurred: {str(e)}\")\n            \n    def save_to_csv(self, output_file):\n        \"\"\"\n        Save the closing prices to a CSV file.\n        \n        Args:\n            output_file (str): Path to save the CSV file\n        \"\"\"\n        if self.dataframe is not None:\n            self.dataframe.to_csv(output_file, index=False)\n            print(f\"Successfully saved closing prices to {output_file}\")\n        else:\n            print(\"No data available. Please call fetch_closing_prices() first.\")\n            \n    def visualize_data(self, save_path=None):\n        \"\"\"\n        Create visualizations for the stock data.\n        \n        Args:\n            save_path (str, optional): Path to save the visualization. If None, the plot will be displayed.\n        \"\"\"\n        if self.dataframe is None:\n            print(\"No data available. Please call fetch_closing_prices() first.\")\n            return\n            \n        try:\n            # Set the style\n            plt.style.use('seaborn-v0_8')  # Use a valid style name\n            \n            # Create a figure with subplots\n            fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n            \n            # Plot 1: Closing Price Over Time\n            sns.lineplot(data=self.dataframe, x='Date', y='Close', ax=ax1)\n            ax1.set_title(f'{self.ticker} Closing Price Over Time')\n            ax1.set_xlabel('Date')\n            ax1.set_ylabel('Price ($)')\n            ax1.grid(True)\n            \n            # Calculate daily returns\n            self.dataframe['Daily_Return'] = self.dataframe['Close'].pct_change()\n            \n            # Plot 2: Daily Returns Distribution\n            sns.histplot(data=self.dataframe, x='Daily_Return', bins=50, ax=ax2)\n            ax2.set_title(f'{self.ticker} Daily Returns Distribution')\n            ax2.set_xlabel('Daily Return')\n            ax2.set_ylabel('Frequency')\n            ax2.grid(True)\n            \n            # Add some statistics\n            mean_return = self.dataframe['Daily_Return'].mean()\n            std_return = self.dataframe['Daily_Return'].std()\n            ax2.axvline(mean_return, color='r', linestyle='--', label=f'Mean: {mean_return:.4f}')\n            ax2.axvline(mean_return + std_return, color='g', linestyle='--', label=f'Std Dev: {std_return:.4f}')\n            ax2.axvline(mean_return - std_return, color='g', linestyle='--')\n            ax2.legend()\n            \n            plt.tight_layout()\n            \n            if save_path:\n                plt.savefig(save_path)\n                print(f\"Visualization saved to {save_path}\")\n            else:\n                plt.show()\n                \n            plt.close()\n            \n        except Exception as e:\n            print(f\"Error creating visualization: {str(e)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T22:38:38.231621Z","iopub.execute_input":"2025-04-19T22:38:38.231832Z","iopub.status.idle":"2025-04-19T22:38:39.769602Z","shell.execute_reply.started":"2025-04-19T22:38:38.231813Z","shell.execute_reply":"2025-04-19T22:38:39.768478Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# # Example usage and testing for the module\n# stock_data_test = StockData(\n#         ticker='GOOG',\n#         start_date='2024-01-01',\n#         end_date='2025-04-19'\n#     )\n    \n# # Fetch the closing prices\n# stock_data_test.fetch_closing_prices()\n\n# # Display\n# print(stock_data_test.dataframe.head())\n\n# # Save to CSV\n# stock_data_test.save_to_csv(\"google_stock_prices.csv\")\n    \n# # Create visualizations\n# stock_data_test.visualize_data() \n# stock_data_test.visualize_data(\"google_stock_analysis.png\") ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T22:38:39.771623Z","iopub.execute_input":"2025-04-19T22:38:39.772159Z","iopub.status.idle":"2025-04-19T22:38:39.775843Z","shell.execute_reply.started":"2025-04-19T22:38:39.772137Z","shell.execute_reply":"2025-04-19T22:38:39.774956Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## 2. Holdout Validation Model <a name=\"holdout\"></a>\n\nThe `StockModelHoldout` class implements a holdout validation approach for stock price forecasting using Prophet.\n\n### Features:\n- Split data into training (80%) and testing (20%) sets\n- Train Prophet model on historical data\n- Make predictions on test data\n- Calculate performance metrics (MAE, MSE, RMSE, R²)\n- Visualize actual vs predicted values\n\n### Dependencies:\n- prophet: For time series forecasting\n- scikit-learn: For performance metrics","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom prophet import Prophet\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nclass StockModelHoldout:\n    def __init__(self, stock_data):\n        \"\"\"\n        Initialize StockModelHoldout with StockData object.\n        \n        Args:\n            stock_data (StockData): StockData object containing the stock data\n        \"\"\"\n        if not isinstance(stock_data, StockData):\n            raise ValueError(\"Input must be a StockData object\")\n            \n        self.stock_data = stock_data\n        self.train_data = None\n        self.test_data = None\n        self.model = None\n        self.forecast = None\n        self.metrics = None\n        \n    def split_data(self, test_size=0.2):\n        \"\"\"\n        Split the data into training and testing sets.\n        \n        Args:\n            test_size (float): Proportion of data to use for testing (default: 0.2)\n        \"\"\"\n        if self.stock_data.dataframe is None:\n            raise ValueError(\"No data available. Please fetch data first.\")\n            \n        # Sort data by date\n        df = self.stock_data.dataframe.sort_values('Date')\n        \n        # Calculate split index\n        split_idx = int(len(df) * (1 - test_size))\n        \n        # Split the data\n        self.train_data = df.iloc[:split_idx].copy()\n        self.test_data = df.iloc[split_idx:].copy()\n        \n        # Prepare data for Prophet\n        self.train_data = self.train_data.rename(columns={'Date': 'ds', 'Close': 'y'})\n        self.test_data = self.test_data.rename(columns={'Date': 'ds', 'Close': 'y'})\n        \n    def train_model(self):\n        \"\"\"\n        Train the Prophet model on the training data.\n        \"\"\"\n        if self.train_data is None:\n            raise ValueError(\"No training data available. Please split data first.\")\n            \n        # Initialize and fit the model\n        self.model = Prophet()\n        self.model.fit(self.train_data)\n        \n    def make_forecast(self):\n        \"\"\"\n        Make forecasts on the test data.\n        \"\"\"\n        if self.model is None:\n            raise ValueError(\"No trained model available. Please train the model first.\")\n            \n        # Create future dataframe for test dates\n        future = self.test_data[['ds']]\n        \n        # Make predictions\n        self.forecast = self.model.predict(future)\n        \n    def calculate_metrics(self):\n        \"\"\"\n        Calculate performance metrics for the forecast.\n        \"\"\"\n        if self.forecast is None:\n            raise ValueError(\"No forecast available. Please make forecast first.\")\n            \n        # Extract actual and predicted values\n        y_true = self.test_data['y'].values\n        y_pred = self.forecast['yhat'].values\n        \n        # Calculate metrics\n        self.metrics = {\n            'MAE': mean_absolute_error(y_true, y_pred),\n            'MSE': mean_squared_error(y_true, y_pred),\n            'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),\n            'R2': r2_score(y_true, y_pred)\n        }\n        \n    def visualize_forecast(self, save_path=None):\n        \"\"\"\n        Visualize the actual vs predicted values over the test period.\n        \n        Args:\n            save_path (str, optional): Path to save the visualization. If None, the plot will be displayed.\n        \"\"\"\n        if self.forecast is None:\n            raise ValueError(\"No forecast available. Please make forecast first.\")\n            \n        try:\n            # Set the style\n            plt.style.use('seaborn-v0_8')\n            \n            # Create the plot\n            plt.figure(figsize=(12, 6))\n            \n            # Plot actual values\n            plt.plot(self.test_data['ds'], self.test_data['y'], \n                    label='Actual', color='blue', linewidth=2)\n            \n            # Plot predicted values\n            plt.plot(self.test_data['ds'], self.forecast['yhat'], \n                    label='Predicted', color='red', linestyle='--', linewidth=2)\n            \n            # Add confidence intervals\n            plt.fill_between(self.test_data['ds'], \n                           self.forecast['yhat_lower'], \n                           self.forecast['yhat_upper'],\n                           color='gray', alpha=0.2, label='Confidence Interval')\n            \n            # Customize the plot\n            plt.title(f'{self.stock_data.ticker} Stock Price: Actual vs Predicted')\n            plt.xlabel('Date')\n            plt.ylabel('Price ($)')\n            plt.legend()\n            plt.grid(True)\n            \n            # Rotate x-axis labels for better readability\n            plt.xticks(rotation=45)\n            \n            # Adjust layout\n            plt.tight_layout()\n            \n            if save_path:\n                plt.savefig(save_path)\n                print(f\"Visualization saved to {save_path}\")\n            else:\n                plt.show()\n                \n            plt.close()\n            \n        except Exception as e:\n            print(f\"Error creating visualization: {str(e)}\")\n        \n    def run_analysis(self, test_size=0.2):\n        \"\"\"\n        Run the complete analysis pipeline.\n        \n        Args:\n            test_size (float): Proportion of data to use for testing (default: 0.2)\n        \"\"\"\n        self.split_data(test_size)\n        self.train_model()\n        self.make_forecast()\n        self.calculate_metrics()\n        \n        return self.metrics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T22:38:39.776598Z","iopub.execute_input":"2025-04-19T22:38:39.776789Z","iopub.status.idle":"2025-04-19T22:38:40.257915Z","shell.execute_reply.started":"2025-04-19T22:38:39.776772Z","shell.execute_reply":"2025-04-19T22:38:40.256911Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# # Example usage and testing for StockModelHoldout module\n# # Create StockData object\n# stock_data = StockData(\n#     ticker=\"GOOG\",\n#     start_date=\"2020-01-01\",\n#     end_date=\"2025-04-19\"\n# )\n\n# # Fetch the data\n# stock_data.fetch_closing_prices()\n# print(stock_data.dataframe.head())\n\n# # Create and run the model\n# model = StockModelHoldout(stock_data)\n# metrics = model.run_analysis()\n\n# # Print the results\n# print(\"\\nModel Performance Metrics:\")\n# for metric, value in metrics.items():\n#     print(f\"{metric}: {value:.4f}\")\n    \n# # Create visualization\n# model.visualize_forecast() \n# model.visualize_forecast(\"stock_forecast.png\") ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T22:38:40.258710Z","iopub.execute_input":"2025-04-19T22:38:40.258923Z","iopub.status.idle":"2025-04-19T22:38:40.262600Z","shell.execute_reply.started":"2025-04-19T22:38:40.258904Z","shell.execute_reply":"2025-04-19T22:38:40.261960Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## 3. Hyperparameter Optimization <a name=\"hyperopt\"></a>\n\nThe `StockHyperopt` class implements hyperparameter optimization for Prophet models using hyperopt.\n\n### Features:\n- Define hyperparameter search space\n- Optimize Prophet model parameters\n- Train final model with best parameters\n- Make future predictions\n- Visualize forecast results\n\n### Dependencies:\n- hyperopt: For Bayesian optimization\n- prophet: For time series forecasting","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom prophet import Prophet\nfrom hyperopt import fmin, tpe, hp, STATUS_OK, Trials\nfrom datetime import datetime, timedelta\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nclass StockHyperopt:\n    def __init__(self, stock_data):\n        \"\"\"\n        Initialize StockHyperopt with StockData object.\n        \n        Args:\n            stock_data (StockData): StockData object containing the stock data\n        \"\"\"\n        if not isinstance(stock_data, StockData):\n            raise ValueError(\"Input must be a StockData object\")\n            \n        self.stock_data = stock_data\n        self.model = None\n        self.best_params = None\n        self.forecast = None\n        \n    def prepare_data(self):\n        \"\"\"\n        Prepare data for Prophet model.\n        \"\"\"\n        if self.stock_data.dataframe is None:\n            raise ValueError(\"No data available. Please fetch data first.\")\n            \n        # Sort data by date\n        self.df = self.stock_data.dataframe.sort_values('Date')\n        \n        # Prepare data for Prophet\n        self.df = self.df.rename(columns={'Date': 'ds', 'Close': 'y'})\n        \n    def objective(self, params):\n        \"\"\"\n        Objective function for hyperparameter optimization.\n        \n        Args:\n            params (dict): Hyperparameters to evaluate\n            \n        Returns:\n            dict: Dictionary containing loss and status\n        \"\"\"\n        # Create Prophet model with current parameters\n        model = Prophet(\n            changepoint_prior_scale=params['changepoint_prior_scale'],\n            seasonality_prior_scale=params['seasonality_prior_scale'],\n            holidays_prior_scale=params['holidays_prior_scale'],\n            seasonality_mode=params['seasonality_mode']\n        )\n        \n        # Fit the model\n        model.fit(self.df)\n        \n        # Make predictions\n        future = model.make_future_dataframe(periods=30)\n        forecast = model.predict(future)\n        \n        # Calculate RMSE on the last 30 days\n        y_true = self.df['y'].values[-30:]\n        y_pred = forecast['yhat'].values[-30:]\n        rmse = np.sqrt(np.mean((y_true - y_pred) ** 2))\n        \n        return {'loss': rmse, 'status': STATUS_OK}\n        \n    def optimize_hyperparameters(self, max_evals=50):\n        \"\"\"\n        Optimize hyperparameters using hyperopt.\n        \n        Args:\n            max_evals (int): Maximum number of evaluations (default: 50)\n        \"\"\"\n        if self.df is None:\n            raise ValueError(\"No data available. Please prepare data first.\")\n            \n        # Define the search space\n        space = {\n            'changepoint_prior_scale': hp.loguniform('changepoint_prior_scale', -5, 0),\n            'seasonality_prior_scale': hp.loguniform('seasonality_prior_scale', -5, 0),\n            'holidays_prior_scale': hp.loguniform('holidays_prior_scale', -5, 0),\n            'seasonality_mode': hp.choice('seasonality_mode', ['additive', 'multiplicative'])\n        }\n        \n        # Run optimization\n        trials = Trials()\n        best = fmin(\n            fn=self.objective,\n            space=space,\n            algo=tpe.suggest,\n            max_evals=max_evals,\n            trials=trials\n        )\n        \n        # Get the best parameters\n        self.best_params = {\n            'changepoint_prior_scale': best['changepoint_prior_scale'],\n            'seasonality_prior_scale': best['seasonality_prior_scale'],\n            'holidays_prior_scale': best['holidays_prior_scale'],\n            'seasonality_mode': ['additive', 'multiplicative'][best['seasonality_mode']]\n        }\n        \n    def train_best_model(self):\n        \"\"\"\n        Train the Prophet model with the best hyperparameters.\n        \"\"\"\n        if self.best_params is None:\n            raise ValueError(\"No optimized parameters available. Please run optimize_hyperparameters first.\")\n            \n        # Create Prophet model with best parameters\n        self.model = Prophet(\n            changepoint_prior_scale=self.best_params['changepoint_prior_scale'],\n            seasonality_prior_scale=self.best_params['seasonality_prior_scale'],\n            holidays_prior_scale=self.best_params['holidays_prior_scale'],\n            seasonality_mode=self.best_params['seasonality_mode']\n        )\n        \n        # Fit the model\n        self.model.fit(self.df)\n        \n    def forecast_next_year(self):\n        \"\"\"\n        Forecast stock prices for the next year.\n        \"\"\"\n        if self.model is None:\n            raise ValueError(\"No trained model available. Please train the model first.\")\n            \n        # Create future dataframe for next year\n        future = self.model.make_future_dataframe(periods=365)\n        \n        # Make predictions\n        self.forecast = self.model.predict(future)\n        \n    def visualize_forecast(self, save_path=None):\n        \"\"\"\n        Visualize the forecast for the next year.\n        \n        Args:\n            save_path (str, optional): Path to save the visualization. If None, the plot will be displayed.\n        \"\"\"\n        if self.forecast is None:\n            raise ValueError(\"No forecast available. Please run forecast_next_year first.\")\n            \n        try:\n            # Set the style\n            plt.style.use('seaborn-v0_8')\n            \n            # Create the plot\n            plt.figure(figsize=(12, 6))\n            \n            # Plot historical data\n            plt.plot(self.df['ds'], self.df['y'], \n                    label='Historical', color='blue', linewidth=2)\n            \n            # Plot forecast\n            plt.plot(self.forecast['ds'], self.forecast['yhat'], \n                    label='Forecast', color='red', linestyle='--', linewidth=2)\n            \n            # Add confidence intervals\n            plt.fill_between(self.forecast['ds'], \n                           self.forecast['yhat_lower'], \n                           self.forecast['yhat_upper'],\n                           color='gray', alpha=0.2, label='Confidence Interval')\n            \n            # Customize the plot\n            plt.title(f'{self.stock_data.ticker} Stock Price Forecast for Next Year')\n            plt.xlabel('Date')\n            plt.ylabel('Price ($)')\n            plt.legend()\n            plt.grid(True)\n            \n            # Rotate x-axis labels for better readability\n            plt.xticks(rotation=45)\n            \n            # Adjust layout\n            plt.tight_layout()\n            \n            if save_path:\n                plt.savefig(save_path)\n                print(f\"Visualization saved to {save_path}\")\n            else:\n                plt.show()\n                \n            plt.close()\n            \n        except Exception as e:\n            print(f\"Error creating visualization: {str(e)}\")\n            \n    def run_analysis(self, max_evals=50):\n        \"\"\"\n        Run the complete analysis pipeline.\n        \n        Args:\n            max_evals (int): Maximum number of evaluations for hyperparameter optimization\n        \"\"\"\n        self.prepare_data()\n        self.optimize_hyperparameters(max_evals)\n        self.train_best_model()\n        self.forecast_next_year()\n        \n        return self.best_params","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T22:38:40.263743Z","iopub.execute_input":"2025-04-19T22:38:40.264401Z","iopub.status.idle":"2025-04-19T22:38:41.018142Z","shell.execute_reply.started":"2025-04-19T22:38:40.264363Z","shell.execute_reply":"2025-04-19T22:38:41.017115Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# # Example run and testing StockHyperopt module\n# # Create StockData object\n# stock_data = StockData(\n#     ticker=\"GOOG\",\n#     start_date=\"2020-01-01\",\n#     end_date=\"2025-04-19\"\n# )\n\n# # Fetch the data\n# stock_data.fetch_closing_prices()\n\n# # Create and run the model\n# model = StockHyperopt(stock_data)\n# best_params = model.run_analysis()\n\n# # Print the best parameters\n# print(\"\\nBest Hyperparameters:\")\n# for param, value in best_params.items():\n#     print(f\"{param}: {value}\")\n    \n# # Create visualization\n# model.visualize_forecast()\n# model.visualize_forecast(\"stock_forecast_next_year.png\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T22:38:41.018877Z","iopub.execute_input":"2025-04-19T22:38:41.019434Z","iopub.status.idle":"2025-04-19T22:38:41.023468Z","shell.execute_reply.started":"2025-04-19T22:38:41.019409Z","shell.execute_reply":"2025-04-19T22:38:41.022318Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"## 4. AI-Powered Analysis Agent <a name=\"agent\"></a>\n\nThe `StockAgent` class implements an AI-powered agent that uses the Gemini API to assist with stock analysis tasks.\n\n### Features:\n- Natural language understanding using Gemini API\n- Automated stock data fetching and visualization\n- Holdout validation analysis\n- Optimized forecasting\n- Interactive assistance\n\n### Dependencies:\n- langchain_google_genai: For Gemini API integration\n- langchain, langgraph\n- All previous components (StockData, StockModelHoldout, StockHyperopt)","metadata":{}},{"cell_type":"code","source":"import os\nfrom typing import Dict, List, TypedDict, Annotated, Sequence\nfrom langchain_google_genai import ChatGoogleGenerativeAI\nfrom langchain_core.messages import HumanMessage, AIMessage\nfrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\nfrom langgraph.graph import StateGraph, END\nimport matplotlib\nmatplotlib.use('Agg')  # Use Agg backend to avoid GUI issues\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime, timedelta\nimport re\nfrom IPython.display import Image, display\n\n# Load environment variables\n# load_dotenv()\n\n# Define the state type\nclass AgentState(TypedDict):\n    messages: Annotated[Sequence[HumanMessage | AIMessage], \"The conversation history\"]\n    stock_data: StockData | None\n    holdout_model: StockModelHoldout | None\n    hyperopt_model: StockHyperopt | None\n    last_action: str | None\n\n# Initialize the LLM\nllm = ChatGoogleGenerativeAI(\n    model=\"gemini-2.0-flash\",\n    google_api_key=os.getenv(\"GOOGLE_API_KEY\"),\n    temperature=0.7\n)\n\n# Define the system prompt\nsystem_prompt = \"\"\"You are a helpful stock market analysis assistant. Your role is to:\n1. Understand user requests about stock data\n2. Extract stock tickers and date ranges from user input\n3. Perform appropriate stock analysis (historical data, forecasting, or hyperparameter tuning)\n4. Provide clear and informative responses\n\nWhen analyzing stocks, you can:\n- Show historical price data\n- Create forecasts using Prophet\n- Tune hyperparameters for better predictions\n- Visualize results\n\nAlways be clear about what you're doing and explain the results in a way that's easy to understand.\"\"\"\n\n# Create the prompt template\nprompt = ChatPromptTemplate.from_messages([\n    (\"system\", system_prompt),\n    MessagesPlaceholder(variable_name=\"messages\"),\n])\n\ndef parse_relative_date(date_str: str) -> str:\n    \"\"\"\n    Convert relative date expressions to YYYY-MM-DD format.\n    \n    Args:\n        date_str (str): Date string that might contain relative expressions\n        \n    Returns:\n        str: Date in YYYY-MM-DD format\n    \"\"\"\n    today = datetime.now()\n    \n    # Handle \"today\"\n    if date_str.lower() == \"today\":\n        return today.strftime('%Y-%m-%d')\n    \n    # Handle \"X years ago\"\n    match = re.match(r'(\\d+)\\s+years?\\s+ago', date_str.lower())\n    if match:\n        years = int(match.group(1))\n        return (today - timedelta(days=years*365)).strftime('%Y-%m-%d')\n    \n    # Handle \"X months ago\"\n    match = re.match(r'(\\d+)\\s+months?\\s+ago', date_str.lower())\n    if match:\n        months = int(match.group(1))\n        return (today - timedelta(days=months*30)).strftime('%Y-%m-%d')\n    \n    # Handle \"X days ago\"\n    match = re.match(r'(\\d+)\\s+days?\\s+ago', date_str.lower())\n    if match:\n        days = int(match.group(1))\n        return (today - timedelta(days=days)).strftime('%Y-%m-%d')\n    \n    # If it's already in YYYY-MM-DD format, return as is\n    try:\n        datetime.strptime(date_str, '%Y-%m-%d')\n        return date_str\n    except ValueError:\n        # If we can't parse it, return today's date\n        return today.strftime('%Y-%m-%d')\n\ndef create_visualization(data, title, xlabel, ylabel, save_path=None):\n    \"\"\"\n    Create and save a visualization without displaying it.\n    \n    Args:\n        data: DataFrame containing the data to plot\n        title: Title of the plot\n        xlabel: Label for x-axis\n        ylabel: Label for y-axis\n        save_path: Path to save the plot (optional)\n    \"\"\"\n    try:\n        plt.style.use('seaborn-v0_8')\n        fig, ax = plt.subplots(figsize=(12, 6))\n        \n        # Plot the data\n        ax.plot(data.index, data.values, label=ylabel, color='blue', linewidth=2)\n        \n        # Customize the plot\n        ax.set_title(title)\n        ax.set_xlabel(xlabel)\n        ax.set_ylabel(ylabel)\n        ax.legend()\n        ax.grid(True)\n        plt.xticks(rotation=45)\n        plt.tight_layout()\n        \n        # Save the plot if path is provided\n        if save_path:\n            plt.savefig(save_path)\n        \n        # Close the figure to free memory\n        plt.close(fig)\n        \n        return True\n    except Exception as e:\n        print(f\"Error creating visualization: {str(e)}\")\n        return False\n\n# Define the nodes in the graph\ndef extract_stock_info(state: AgentState) -> AgentState:\n    \"\"\"Extract stock information from user input.\"\"\"\n    try:\n        # Get the last user message\n        last_message = state[\"messages\"][-1].content\n        \n        # Use LLM to extract stock info\n        response = llm.invoke([\n            HumanMessage(content=f\"\"\"Extract the stock ticker symbol and date range from this text: {last_message}\n            Return the information in this format:\n            TICKER: [ticker]\n            START_DATE: [start_date]\n            END_DATE: [end_date]\n            If any information is missing, use defaults:\n            - Default start_date: 3 years ago\n            - Default end_date: today\"\"\")\n        ])\n        \n        # Parse the response\n        info = {}\n        for line in response.content.split('\\n'):\n            if ':' in line:\n                key, value = line.split(':', 1)\n                info[key.strip()] = value.strip()\n        \n        # Parse dates\n        ticker = info.get('TICKER', '')\n        start_date = parse_relative_date(info.get('START_DATE', '3 years ago'))\n        end_date = parse_relative_date(info.get('END_DATE', 'today'))\n        \n        if ticker:\n            state[\"stock_data\"] = StockData(ticker, start_date, end_date)\n            state[\"stock_data\"].fetch_closing_prices()\n            \n        return state\n    except Exception as e:\n        state[\"last_action\"] = f\"Error extracting stock info: {str(e)}\"\n        return state\n\ndef analyze_historical_data(state: AgentState) -> AgentState:\n    \"\"\"Analyze and visualize historical stock data.\"\"\"\n    try:\n        if state[\"stock_data\"] and state[\"stock_data\"].dataframe is not None:\n            # Create visualization using the helper function\n            success = create_visualization(\n                data=state[\"stock_data\"].dataframe['Close'],\n                title=f'{state[\"stock_data\"].ticker} Historical Stock Price',\n                xlabel='Date',\n                ylabel='Price ($)',\n                save_path=f\"{state['stock_data'].ticker}_historical.png\"\n            )\n            \n            if success:\n                state[\"last_action\"] = f\"Historical analysis completed. Plot saved as {state['stock_data'].ticker}_historical.png\"\n            else:\n                state[\"last_action\"] = \"Error creating historical visualization\"\n        else:\n            state[\"last_action\"] = \"No stock data available for analysis\"\n            \n        return state\n    except Exception as e:\n        state[\"last_action\"] = f\"Error in historical analysis: {str(e)}\"\n        return state\n\ndef run_holdout_analysis(state: AgentState) -> AgentState:\n    \"\"\"Run holdout analysis and create forecast.\"\"\"\n    try:\n        if state[\"stock_data\"]:\n            state[\"holdout_model\"] = StockModelHoldout(state[\"stock_data\"])\n            metrics = state[\"holdout_model\"].run_analysis()\n            \n            # Create visualization using the helper function\n            success = create_visualization(\n                data=state[\"holdout_model\"].forecast['yhat'],\n                title=f'{state[\"stock_data\"].ticker} Forecast',\n                xlabel='Date',\n                ylabel='Predicted Price ($)',\n                save_path=f\"{state['stock_data'].ticker}_holdout_forecast.png\"\n            )\n            \n            if success:\n                metrics_msg = \"\\n\".join([f\"{metric}: {value:.4f}\" for metric, value in metrics.items()])\n                state[\"last_action\"] = f\"Holdout analysis completed. Metrics:\\n{metrics_msg}\\nForecast saved as {state['stock_data'].ticker}_holdout_forecast.png\"\n            else:\n                state[\"last_action\"] = \"Error creating forecast visualization\"\n        else:\n            state[\"last_action\"] = \"No stock data available for holdout analysis\"\n            \n        return state\n    except Exception as e:\n        state[\"last_action\"] = f\"Error in holdout analysis: {str(e)}\"\n        return state\n\ndef run_hyperopt_analysis(state: AgentState) -> AgentState:\n    \"\"\"Run hyperopt analysis and create optimized forecast.\"\"\"\n    try:\n        if state[\"stock_data\"]:\n            state[\"hyperopt_model\"] = StockHyperopt(state[\"stock_data\"])\n            best_params = state[\"hyperopt_model\"].run_analysis()\n            \n            # Create visualization using the helper function\n            success = create_visualization(\n                data=state[\"hyperopt_model\"].forecast['yhat'],\n                title=f'{state[\"stock_data\"].ticker} Optimized Forecast',\n                xlabel='Date',\n                ylabel='Predicted Price ($)',\n                save_path=f\"{state['stock_data'].ticker}_hyperopt_forecast.png\"\n            )\n            \n            if success:\n                params_msg = \"\\n\".join([f\"{param}: {value}\" for param, value in best_params.items()])\n                state[\"last_action\"] = f\"Hyperopt analysis completed. Best parameters:\\n{params_msg}\\nForecast saved as {state['stock_data'].ticker}_hyperopt_forecast.png\"\n            else:\n                state[\"last_action\"] = \"Error creating optimized forecast visualization\"\n        else:\n            state[\"last_action\"] = \"No stock data available for hyperopt analysis\"\n            \n        return state\n    except Exception as e:\n        state[\"last_action\"] = f\"Error in hyperopt analysis: {str(e)}\"\n        return state\n\ndef generate_response(state: AgentState) -> AgentState:\n    \"\"\"Generate a response based on the last action.\"\"\"\n    try:\n        # Get the conversation history\n        messages = state[\"messages\"]\n        \n        # Add the last action to the context\n        context = f\"Last action: {state['last_action']}\\n\\nUser's last message: {messages[-1].content}\"\n        \n        # Generate response\n        response = llm.invoke([\n            HumanMessage(content=context)\n        ])\n        \n        # Add the response to the conversation history\n        state[\"messages\"].append(AIMessage(content=response.content))\n        \n        return state\n    except Exception as e:\n        state[\"messages\"].append(AIMessage(content=f\"Error generating response: {str(e)}\"))\n        return state\n\n# Create the graph\nworkflow = StateGraph(AgentState)\n\n# Add nodes\nworkflow.add_node(\"extract_stock_info\", extract_stock_info)\nworkflow.add_node(\"analyze_historical\", analyze_historical_data)\nworkflow.add_node(\"run_holdout\", run_holdout_analysis)\nworkflow.add_node(\"run_hyperopt\", run_hyperopt_analysis)\nworkflow.add_node(\"generate_response\", generate_response)\n\n# Define edges\ndef route_based_on_intent(state: AgentState) -> str:\n    \"\"\"Route to the appropriate node based on user intent.\"\"\"\n    last_message = state[\"messages\"][-1].content.lower()\n    \n    # Check for specific keywords in the message\n    if \"forecast\" in last_message and (\"tune\" in last_message or \"optimize\" in last_message or \"hyperparameter\" in last_message):\n        return \"run_hyperopt\"\n    elif \"forecast\" in last_message or \"predict\" in last_message:\n        return \"run_holdout\"\n    elif \"historical\" in last_message or \"price\" in last_message or \"show\" in last_message:\n        return \"analyze_historical\"\n    else:\n        # If no specific intent is detected, ask the LLM to determine the intent\n        try:\n            response = llm.invoke([\n                HumanMessage(content=f\"\"\"Based on this user message, determine which analysis to perform:\n                {last_message}\n                \n                Return ONLY one of these exact options:\n                - analyze_historical\n                - run_holdout\n                - run_hyperopt\n                - generate_response\n                \n                Choose based on the user's intent to:\n                - analyze_historical: for showing historical data or prices\n                - run_holdout: for forecasting or predicting future prices\n                - run_hyperopt: for optimizing or tuning forecast models\n                - generate_response: for general questions or clarifications\"\"\")\n            ])\n            return response.content.strip()\n        except Exception as e:\n            print(f\"Error determining intent: {str(e)}\")\n            return \"generate_response\"\n\n# Add edges\nworkflow.add_conditional_edges(\n    \"extract_stock_info\",\n    route_based_on_intent,\n    {\n        \"analyze_historical\": \"analyze_historical\",\n        \"run_holdout\": \"run_holdout\",\n        \"run_hyperopt\": \"run_hyperopt\",\n        \"generate_response\": \"generate_response\"\n    }\n)\n\nworkflow.add_edge(\"analyze_historical\", \"generate_response\")\nworkflow.add_edge(\"run_holdout\", \"generate_response\")\nworkflow.add_edge(\"run_hyperopt\", \"generate_response\")\nworkflow.add_edge(\"generate_response\", END)\n\n# Set the entry point\nworkflow.set_entry_point(\"extract_stock_info\")\n\n# Compile the graph\napp = workflow.compile()\n\n\n# Image(app.get_graph().draw_mermaid_png())\n\nclass StockAgent:\n    def __init__(self):\n        \"\"\"Initialize the StockAgent.\"\"\"\n        self.state = {\n            \"messages\": [],\n            \"stock_data\": None,\n            \"holdout_model\": None,\n            \"hyperopt_model\": None,\n            \"last_action\": None\n        }\n        \n    def process_user_input(self, user_input: str) -> str:\n        \"\"\"\n        Process user input and return a response.\n        \n        Args:\n            user_input (str): The user's input message\n            \n        Returns:\n            str: The agent's response\n        \"\"\"\n        try:\n            # Add user message to state\n            self.state[\"messages\"].append(HumanMessage(content=user_input))\n            \n            # Run the workflow\n            self.state = app.invoke(self.state)\n            \n            # Return the last AI message\n            return self.state[\"messages\"][-1].content\n            \n        except Exception as e:\n            return f\"Error processing request: {str(e)}\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T22:38:41.024423Z","iopub.execute_input":"2025-04-19T22:38:41.024670Z","iopub.status.idle":"2025-04-19T22:38:43.277653Z","shell.execute_reply.started":"2025-04-19T22:38:41.024654Z","shell.execute_reply":"2025-04-19T22:38:43.276824Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"## Example Usage\n\nLet's see how to use the complete stock analysis system:","metadata":{}},{"cell_type":"code","source":"agent = StockAgent()\n    \n# Example interactions\nprint(agent.process_user_input(\"Show me the historical stock price of GOOG\"))\nprint(agent.process_user_input(\"Forecast the stock price of GOOG\"))\nprint(agent.process_user_input(\"Tune hyperparameters and forecast the stock price of GOOG\")) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T22:38:43.278515Z","iopub.execute_input":"2025-04-19T22:38:43.279144Z","iopub.status.idle":"2025-04-19T22:39:12.067530Z","shell.execute_reply.started":"2025-04-19T22:38:43.279119Z","shell.execute_reply":"2025-04-19T22:39:12.066419Z"}},"outputs":[{"name":"stdout","text":"YF.download() has changed argument auto_adjust default to True\n","output_type":"stream"},{"name":"stderr","text":"[*********************100%***********************]  1 of 1 completed\n","output_type":"stream"},{"name":"stdout","text":"Successfully fetched closing prices for GOOG\nOkay, I've already completed the historical analysis of GOOG and saved the plot as \"GOOG_historical.png\".  Since I can't directly display images in this text-based interface, you'll need to access the \"GOOG_historical.png\" file to see the plot of the historical stock price of GOOG. Look for it in the location where the code was executed.\n","output_type":"stream"},{"name":"stderr","text":"[*********************100%***********************]  1 of 1 completed\n","output_type":"stream"},{"name":"stdout","text":"Successfully fetched closing prices for GOOG\n","output_type":"stream"},{"name":"stderr","text":"22:38:47 - cmdstanpy - INFO - Chain [1] start processing\n22:38:47 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":"Okay, I've already completed a holdout analysis and saved a visualization of that forecast as `GOOG_holdout_forecast.png`.  That holdout analysis *is* a forecast of the stock price of GOOG, but it's specifically for the holdout period (the portion of the data I set aside for evaluation).\n\nTo provide a more useful response, I need to understand what *kind* of forecast you're looking for.  Specifically:\n\n1.  **Forecast Horizon:** How far into the future do you want the forecast? (e.g., next day, next week, next month, next year?)\n2.  **Data to Use:** Do you want me to use only the data I trained on originally, or should I retrain on the *entire* dataset now that I've evaluated on the holdout set?  Retraining on the entire dataset *might* give a slightly better forecast, but it means I can't provide a separate evaluation metric.\n3.  **Format:** Do you want a table of predicted values, a textual description of the predicted trend, or are you primarily interested in the visualization I already saved (`GOOG_holdout_forecast.png`)?\n\n**In the meantime, consider the following based on the holdout analysis:**\n\n*   The metrics show a significant error (RMSE of 27.63) and a very poor R-squared (-2.71).  This suggests the model isn't performing well in predicting GOOG's stock price.  **The forecast should be viewed with extreme caution.**  The negative R-squared indicates the model is worse than simply predicting the average price.\n\n**Please provide more details about your forecasting request so I can generate a more relevant and useful forecast.**\n","output_type":"stream"},{"name":"stderr","text":"[*********************100%***********************]  1 of 1 completed","output_type":"stream"},{"name":"stdout","text":"Successfully fetched closing prices for GOOG\n  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]","output_type":"stream"},{"name":"stderr","text":"\n22:38:50 - cmdstanpy - INFO - Chain [1] start processing\n22:38:50 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":"  2%|▏         | 1/50 [00:00<00:24,  1.98trial/s, best loss: 15.115530471394264]","output_type":"stream"},{"name":"stderr","text":"22:38:50 - cmdstanpy - INFO - Chain [1] start processing\n22:38:51 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":"  4%|▍         | 2/50 [00:00<00:23,  2.03trial/s, best loss: 9.276450070057484] ","output_type":"stream"},{"name":"stderr","text":"22:38:51 - cmdstanpy - INFO - Chain [1] start processing\n22:38:51 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":"  6%|▌         | 3/50 [00:01<00:16,  2.81trial/s, best loss: 9.276450070057484]","output_type":"stream"},{"name":"stderr","text":"22:38:51 - cmdstanpy - INFO - Chain [1] start processing\n22:38:51 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":"  8%|▊         | 4/50 [00:01<00:18,  2.46trial/s, best loss: 9.276450070057484]","output_type":"stream"},{"name":"stderr","text":"22:38:52 - cmdstanpy - INFO - Chain [1] start processing\n22:38:52 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":" 10%|█         | 5/50 [00:02<00:18,  2.37trial/s, best loss: 9.276450070057484]","output_type":"stream"},{"name":"stderr","text":"22:38:52 - cmdstanpy - INFO - Chain [1] start processing\n22:38:52 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":" 12%|█▏        | 6/50 [00:02<00:15,  2.93trial/s, best loss: 9.276450070057484]","output_type":"stream"},{"name":"stderr","text":"22:38:52 - cmdstanpy - INFO - Chain [1] start processing\n22:38:52 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":" 14%|█▍        | 7/50 [00:02<00:12,  3.43trial/s, best loss: 9.276450070057484]","output_type":"stream"},{"name":"stderr","text":"22:38:52 - cmdstanpy - INFO - Chain [1] start processing\n22:38:53 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":" 16%|█▌        | 8/50 [00:02<00:14,  2.94trial/s, best loss: 9.276450070057484]","output_type":"stream"},{"name":"stderr","text":"22:38:53 - cmdstanpy - INFO - Chain [1] start processing\n22:38:53 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":" 18%|█▊        | 9/50 [00:03<00:15,  2.64trial/s, best loss: 9.276450070057484]","output_type":"stream"},{"name":"stderr","text":"22:38:53 - cmdstanpy - INFO - Chain [1] start processing\n22:38:53 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":" 20%|██        | 10/50 [00:03<00:13,  2.96trial/s, best loss: 9.276450070057484]","output_type":"stream"},{"name":"stderr","text":"22:38:54 - cmdstanpy - INFO - Chain [1] start processing\n22:38:54 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":" 22%|██▏       | 11/50 [00:04<00:15,  2.53trial/s, best loss: 9.276450070057484]","output_type":"stream"},{"name":"stderr","text":"22:38:54 - cmdstanpy - INFO - Chain [1] start processing\n22:38:54 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":" 24%|██▍       | 12/50 [00:04<00:12,  3.01trial/s, best loss: 9.276450070057484]","output_type":"stream"},{"name":"stderr","text":"22:38:54 - cmdstanpy - INFO - Chain [1] start processing\n22:38:54 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":" 26%|██▌       | 13/50 [00:04<00:11,  3.16trial/s, best loss: 9.225258648938782]","output_type":"stream"},{"name":"stderr","text":"22:38:55 - cmdstanpy - INFO - Chain [1] start processing\n22:38:55 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":" 28%|██▊       | 14/50 [00:05<00:12,  2.88trial/s, best loss: 9.225258648938782]","output_type":"stream"},{"name":"stderr","text":"22:38:55 - cmdstanpy - INFO - Chain [1] start processing\n22:38:55 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":" 30%|███       | 15/50 [00:05<00:11,  2.97trial/s, best loss: 8.465885285454975]","output_type":"stream"},{"name":"stderr","text":"22:38:55 - cmdstanpy - INFO - Chain [1] start processing\n22:38:55 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":" 32%|███▏      | 16/50 [00:05<00:10,  3.30trial/s, best loss: 8.465885285454975]","output_type":"stream"},{"name":"stderr","text":"22:38:55 - cmdstanpy - INFO - Chain [1] start processing\n22:38:56 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":" 34%|███▍      | 17/50 [00:05<00:08,  3.70trial/s, best loss: 8.465885285454975]","output_type":"stream"},{"name":"stderr","text":"22:38:56 - cmdstanpy - INFO - Chain [1] start processing\n22:38:56 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":" 36%|███▌      | 18/50 [00:06<00:10,  2.93trial/s, best loss: 8.465885285454975]","output_type":"stream"},{"name":"stderr","text":"22:38:56 - cmdstanpy - INFO - Chain [1] start processing\n22:38:56 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":" 38%|███▊      | 19/50 [00:06<00:09,  3.31trial/s, best loss: 8.465885285454975]","output_type":"stream"},{"name":"stderr","text":"22:38:56 - cmdstanpy - INFO - Chain [1] start processing\n22:38:56 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":" 40%|████      | 20/50 [00:06<00:08,  3.61trial/s, best loss: 8.465885285454975]","output_type":"stream"},{"name":"stderr","text":"22:38:57 - cmdstanpy - INFO - Chain [1] start processing\n22:38:57 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":" 42%|████▏     | 21/50 [00:07<00:08,  3.45trial/s, best loss: 8.465885285454975]","output_type":"stream"},{"name":"stderr","text":"22:38:57 - cmdstanpy - INFO - Chain [1] start processing\n22:38:57 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":" 44%|████▍     | 22/50 [00:07<00:09,  2.96trial/s, best loss: 8.465885285454975]","output_type":"stream"},{"name":"stderr","text":"22:38:57 - cmdstanpy - INFO - Chain [1] start processing\n22:38:58 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":" 46%|████▌     | 23/50 [00:07<00:09,  2.78trial/s, best loss: 8.465885285454975]","output_type":"stream"},{"name":"stderr","text":"22:38:58 - cmdstanpy - INFO - Chain [1] start processing\n22:38:58 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":" 48%|████▊     | 24/50 [00:08<00:10,  2.53trial/s, best loss: 8.465885285454975]","output_type":"stream"},{"name":"stderr","text":"22:38:58 - cmdstanpy - INFO - Chain [1] start processing\n22:38:58 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":" 50%|█████     | 25/50 [00:08<00:09,  2.66trial/s, best loss: 7.929258315721762]","output_type":"stream"},{"name":"stderr","text":"22:38:59 - cmdstanpy - INFO - Chain [1] start processing\n22:38:59 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":" 52%|█████▏    | 26/50 [00:08<00:07,  3.05trial/s, best loss: 7.929258315721762]","output_type":"stream"},{"name":"stderr","text":"22:38:59 - cmdstanpy - INFO - Chain [1] start processing\n22:38:59 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":" 54%|█████▍    | 27/50 [00:09<00:07,  2.94trial/s, best loss: 7.929258315721762]","output_type":"stream"},{"name":"stderr","text":"22:38:59 - cmdstanpy - INFO - Chain [1] start processing\n22:38:59 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":" 56%|█████▌    | 28/50 [00:09<00:07,  2.98trial/s, best loss: 7.521937374942735]","output_type":"stream"},{"name":"stderr","text":"22:38:59 - cmdstanpy - INFO - Chain [1] start processing\n22:39:00 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":" 58%|█████▊    | 29/50 [00:10<00:07,  2.68trial/s, best loss: 7.521937374942735]","output_type":"stream"},{"name":"stderr","text":"22:39:00 - cmdstanpy - INFO - Chain [1] start processing\n22:39:00 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":" 60%|██████    | 30/50 [00:10<00:06,  2.88trial/s, best loss: 7.521937374942735]","output_type":"stream"},{"name":"stderr","text":"22:39:00 - cmdstanpy - INFO - Chain [1] start processing\n22:39:01 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":" 62%|██████▏   | 31/50 [00:10<00:07,  2.45trial/s, best loss: 7.521937374942735]","output_type":"stream"},{"name":"stderr","text":"22:39:01 - cmdstanpy - INFO - Chain [1] start processing\n22:39:01 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":" 64%|██████▍   | 32/50 [00:11<00:06,  2.89trial/s, best loss: 7.521937374942735]","output_type":"stream"},{"name":"stderr","text":"22:39:01 - cmdstanpy - INFO - Chain [1] start processing\n22:39:01 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":" 66%|██████▌   | 33/50 [00:11<00:05,  3.33trial/s, best loss: 7.521937374942735]","output_type":"stream"},{"name":"stderr","text":"22:39:01 - cmdstanpy - INFO - Chain [1] start processing\n22:39:01 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":" 68%|██████▊   | 34/50 [00:11<00:05,  3.18trial/s, best loss: 7.521937374942735]","output_type":"stream"},{"name":"stderr","text":"22:39:02 - cmdstanpy - INFO - Chain [1] start processing\n22:39:02 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":" 70%|███████   | 35/50 [00:12<00:05,  2.81trial/s, best loss: 7.521937374942735]","output_type":"stream"},{"name":"stderr","text":"22:39:02 - cmdstanpy - INFO - Chain [1] start processing\n22:39:02 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":" 72%|███████▏  | 36/50 [00:12<00:05,  2.67trial/s, best loss: 7.521937374942735]","output_type":"stream"},{"name":"stderr","text":"22:39:02 - cmdstanpy - INFO - Chain [1] start processing\n22:39:02 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":" 74%|███████▍  | 37/50 [00:12<00:04,  3.06trial/s, best loss: 7.521937374942735]","output_type":"stream"},{"name":"stderr","text":"22:39:03 - cmdstanpy - INFO - Chain [1] start processing\n22:39:03 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":" 76%|███████▌  | 38/50 [00:13<00:04,  2.45trial/s, best loss: 7.521937374942735]","output_type":"stream"},{"name":"stderr","text":"22:39:03 - cmdstanpy - INFO - Chain [1] start processing\n22:39:03 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":" 78%|███████▊  | 39/50 [00:13<00:04,  2.60trial/s, best loss: 7.521937374942735]","output_type":"stream"},{"name":"stderr","text":"22:39:04 - cmdstanpy - INFO - Chain [1] start processing\n22:39:04 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":" 80%|████████  | 40/50 [00:13<00:03,  3.06trial/s, best loss: 7.521937374942735]","output_type":"stream"},{"name":"stderr","text":"22:39:04 - cmdstanpy - INFO - Chain [1] start processing\n22:39:04 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":" 82%|████████▏ | 41/50 [00:14<00:02,  3.41trial/s, best loss: 7.521937374942735]","output_type":"stream"},{"name":"stderr","text":"22:39:04 - cmdstanpy - INFO - Chain [1] start processing\n22:39:04 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":" 84%|████████▍ | 42/50 [00:14<00:02,  3.16trial/s, best loss: 7.521937374942735]","output_type":"stream"},{"name":"stderr","text":"22:39:04 - cmdstanpy - INFO - Chain [1] start processing\n22:39:05 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":" 86%|████████▌ | 43/50 [00:14<00:02,  2.85trial/s, best loss: 7.521937374942735]","output_type":"stream"},{"name":"stderr","text":"22:39:05 - cmdstanpy - INFO - Chain [1] start processing\n22:39:05 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":" 88%|████████▊ | 44/50 [00:15<00:02,  2.50trial/s, best loss: 7.521937374942735]","output_type":"stream"},{"name":"stderr","text":"22:39:05 - cmdstanpy - INFO - Chain [1] start processing\n22:39:06 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":" 90%|█████████ | 45/50 [00:16<00:02,  2.06trial/s, best loss: 7.521937374942735]","output_type":"stream"},{"name":"stderr","text":"22:39:06 - cmdstanpy - INFO - Chain [1] start processing\n22:39:06 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":" 92%|█████████▏| 46/50 [00:16<00:01,  2.19trial/s, best loss: 7.073963341564592]","output_type":"stream"},{"name":"stderr","text":"22:39:06 - cmdstanpy - INFO - Chain [1] start processing\n22:39:06 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":" 94%|█████████▍| 47/50 [00:16<00:01,  2.64trial/s, best loss: 7.073963341564592]","output_type":"stream"},{"name":"stderr","text":"22:39:07 - cmdstanpy - INFO - Chain [1] start processing\n22:39:07 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":" 96%|█████████▌| 48/50 [00:16<00:00,  2.89trial/s, best loss: 7.073963341564592]","output_type":"stream"},{"name":"stderr","text":"22:39:07 - cmdstanpy - INFO - Chain [1] start processing\n22:39:07 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":" 98%|█████████▊| 49/50 [00:17<00:00,  3.29trial/s, best loss: 7.073963341564592]","output_type":"stream"},{"name":"stderr","text":"22:39:07 - cmdstanpy - INFO - Chain [1] start processing\n22:39:07 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":"100%|██████████| 50/50 [00:17<00:00,  2.86trial/s, best loss: 7.073963341564592]","output_type":"stream"},{"name":"stderr","text":"22:39:07 - cmdstanpy - INFO - Chain [1] start processing\n","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"22:39:08 - cmdstanpy - INFO - Chain [1] done processing\n","output_type":"stream"},{"name":"stdout","text":"Okay, the Hyperopt analysis has already completed and identified the best parameters for your forecasting model based on the data you provided. The \"best\" parameters found were:\n\n*   `changepoint_prior_scale`: 0.07688314360359709\n*   `seasonality_prior_scale`: 0.016247123278636654\n*   `holidays_prior_scale`: 0.02405490338495977\n*   `seasonality_mode`: additive\n\nAnd the forecast using these optimized parameters has already been generated and saved as \"GOOG_hyperopt_forecast.png\".\n\n**Therefore, the task is already completed.** No further action is needed based on your request \"Tune hyperparameters and forecast the stock price of GOOG\".  The hyperparameters have been tuned, and the forecast has been generated and saved.\n\n**Possible Next Steps (depending on your intentions):**\n\n*   **Review the Forecast:** Open and examine the \"GOOG_hyperopt_forecast.png\" file to assess the quality of the forecast. Consider:\n    *   Does the forecast look reasonable based on your understanding of GOOG's stock history?\n    *   Are the confidence intervals realistic?\n    *   Does the forecast capture any expected seasonality or trends?\n\n*   **Evaluate the Model:**  If you have historical data that you *didn't* use for training and hyperparameter tuning (a holdout set), you could evaluate the model's performance on that data.  Common metrics include Mean Absolute Error (MAE), Mean Squared Error (MSE), Root Mean Squared Error (RMSE), and Mean Absolute Percentage Error (MAPE). This would give you a more objective measure of how well the model is likely to perform on future data.\n\n*   **Refine the Data:**  Consider if the data can be improved.  Are there any outliers that need to be addressed?  Would adding more historical data improve the model?  Would including relevant external data (e.g., news sentiment, economic indicators) improve the forecast?\n\n*   **Consider a Different Model:** While Prophet is a good starting point, you might explore other time series models (e.g., ARIMA, SARIMA, LSTM networks) to see if they provide better forecasts.\n\n*   **Further Tuning:** While Hyperopt found the \"best\" parameters within the specified search space, you could explore a wider range of parameter values or use different optimization algorithms.\n\nTo help me understand what you'd like to do next, please tell me:\n\n*   Have you reviewed the forecast image?\n*   Are you satisfied with the forecast, or would you like to try to improve it?\n*   Do you have a holdout dataset to evaluate the model's performance?\n*   Are there any other factors you think might be relevant to the forecast (e.g., upcoming product launches, regulatory changes)?\n","output_type":"stream"}],"execution_count":11}]}